{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from typing import List, Set\n",
    "import random\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 17\n",
    "project_base = os.path.dirname(os.path.realpath('.'))\n",
    "print(f'Project base path: {project_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(project_base, 'data', 'WikiLarge_Train.csv')\n",
    "full_df = pd.read_csv(data_path)\n",
    "print(f'full_df column names: {list(full_df)}')\n",
    "print(f'full training data df shape: {full_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced split between the two classes\n",
    "full_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sentence into the induvidual words\n",
    "# no cleaning/tokenization/lemmatization\n",
    "# TODO: try tokenizing or lemmatizing to get more matches with external data sources\n",
    "full_df['sentence_word_list'] = full_df.original_text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in sentence\n",
    "full_df['word_count'] = full_df.sentence_word_list.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length_distribution_df = pd.DataFrame(full_df.groupby('word_count').agg({'label':['count', 'mean']})).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length_distribution_df.columns = ['word_count', 'sentence_count', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_length_distribution_df['majority_class_prob'] = word_length_distribution_df['label'].apply(lambda a: max(a, 1-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(word_length_distribution_df).mark_bar().encode(\n",
    "        x=alt.X('word_count', title=\"Word Count\"),\n",
    "        y=alt.Y('label', title=\"Need To Be Simplified Percent\",axis=alt.Axis(format='%')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = alt.Chart(word_length_distribution_df).mark_line(color='orange').encode(\n",
    "        x=alt.X('word_count', title='Word Count'),\n",
    "        y=alt.Y('majority_class_prob', title=\"Majority Class Percent\",axis=alt.Axis(format='%')))\n",
    "\n",
    "bar = alt.Chart(word_length_distribution_df).mark_bar(opacity=0.7).encode(\n",
    "        x=alt.X('word_count', title='Word Count'),\n",
    "        y=alt.Y('sentence_count', title=\"Sentence Count\"))\n",
    "(bar+line).resolve_scale(y='independent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test =  train_test_split(full_df, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lookup_df = pd.DataFrame(X_train.groupby('word_count').mean()['label']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound = 0.45\n",
    "upper_bound = 0.55\n",
    "correct_count = 0\n",
    "\n",
    "# for every sentence, predict the majority class based on sentence length\n",
    "# if the ratio of need to be simplified : does not need to be simplified\n",
    "# is greater than the lower_bound and less than the upper_bound\n",
    "# make a random guess\n",
    "for idx, row in X_test.iterrows():\n",
    "    current_word_len = row.word_count\n",
    "    word_1_prob = model_lookup_df.loc[model_lookup_df['word_count'] == current_word_len, 'label'].values[0]\n",
    "    if word_1_prob < lower_bound or word_1_prob > upper_bound:\n",
    "        prediction = int(np.round(word_1_prob))\n",
    "    else:\n",
    "        prediction = random.choice([0,1])\n",
    "    if prediction == row.label:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f'{correct_count} of {len(X_test)} guesses correct - {(correct_count / len(X_test)*100):.2f}% correct')\n",
    "# 60.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{correct_count} of {len(X_test)} guesses correct - {(correct_count / len(X_test)*100):.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_len = len(X_test)\n",
    "for lower_bound in np.linspace(0.4, 0.49, 5):\n",
    "    for upper_bound in np.linspace(0.5, 0.6, 5):\n",
    "        correct_count = 0\n",
    "\n",
    "        for idx, row in X_test.iterrows():\n",
    "            current_word_len = row.word_count\n",
    "            word_1_prob = model_lookup_df.loc[model_lookup_df['word_count'] == current_word_len, 'label'].values[0]\n",
    "            if word_1_prob < lower_bound or word_1_prob > upper_bound:\n",
    "                prediction = int(np.round(word_1_prob))\n",
    "            else:\n",
    "#                 prediction = random.choices([0,1], weights=[1-word_1_prob, word_1_prob])\n",
    "                prediction = random.choice([0,1])\n",
    "            if prediction == row.label:\n",
    "                correct_count += 1\n",
    "        print(f'Lower Bound: {lower_bound} - Upper Bound: {upper_bound}')\n",
    "        print(f'{correct_count} of {x_test_len} guesses correct - {(correct_count / x_test_len*100):.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
