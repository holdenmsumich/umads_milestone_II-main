{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Creation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code the add numeric features based on the words in each sentence.  Some of the feature creations steps take a long time, so only run this notebook once and save the output so it can be loaded (instead of created) all times in the future.\n",
    "\n",
    "Jump to [here](#load_x) if you already have completed the feature generation steps and want to add more to the feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from typing import List, Set\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 17\n",
    "project_base = os.path.dirname(os.path.realpath('.'))\n",
    "print(f'Project base path: {project_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(project_base, 'data', 'WikiLarge_Train.csv')\n",
    "full_df = pd.read_csv(data_path)\n",
    "print(f'full_df column names: {list(full_df)}')\n",
    "print(f'full training data df shape: {full_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced split between the two classes\n",
    "full_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_data_path = os.path.join(project_base, 'data', 'WikiLarge_Test.csv')\n",
    "kaggle_full_df = pd.read_csv(kaggle_data_path)\n",
    "print(f'full_df column names: {list(kaggle_full_df)}')\n",
    "print(f'full training data df shape: {kaggle_full_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_full_df.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the kaggle evaluation set and the training set in one df for now\n",
    "# makes features generation a little easier\n",
    "# will split files back out at end of notebook\n",
    "\n",
    "full_df = full_df.append(kaggle_full_df)\n",
    "full_df = full_df.reset_index(drop=True)\n",
    "print(full_df.shape)\n",
    "assert full_df.shape[0] == len(set(full_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split features and labels - not really necessary in this step\n",
    "X = pd.DataFrame(full_df.original_text.copy())\n",
    "y = full_df.label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add features that do not need to be `fit_transformed`\n",
    "\n",
    "Because these features do not depend on a fit and transformation, they will be calculated on the whole data set at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sentence into the induvidual words\n",
    "# no cleaning/tokenization/lemmatization\n",
    "# TODO: try tokenizing or lemmatizing to get more matches with external data sources\n",
    "X['sentence_word_list'] = X.original_text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of words in sentence\n",
    "X['word_count'] = X.sentence_word_list.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dale chale words in sentence\n",
    "dc_path = os.path.join(project_base, 'data', 'dale_chall.txt')\n",
    "dc_df = pd.read_csv(dc_path, header=None)\n",
    "dc_set = set(dc_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dale chale words in each sentence\n",
    "X['dale_chale_overlap_count'] = X.sentence_word_list.apply(lambda a: len(set(a).intersection(dc_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the age of acquisition data\n",
    "# wierd formatting...\n",
    "\n",
    "aoa_path = os.path.join(project_base, 'data', 'AoA_51715_words.csv')\n",
    "aoa_df = pd.read_csv(aoa_path, encoding='Windows-1252')\n",
    "aoa_df.fillna(0, inplace=True)\n",
    "aoa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the word as the index, will make for faster lookups\n",
    "aoa_df_w_index = aoa_df.set_index(['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check df shape\n",
    "aoa_df_w_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of the words, will be used for filtering in next cell\n",
    "aoa_word_set = set(aoa_df.Word.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep words that appear in both the sentence and the age of acquisition df\n",
    "X['aoa_overlap'] = X.sentence_word_list.apply(lambda a: set(a).intersection(aoa_word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# TODO: extract and add as external .py file\n",
    "\n",
    "# max age of acquisition --> how hard is the hardest word in the sentence\n",
    "def get_sentence_max_value(word_set: Set[str], ref_df: pd.DataFrame, search_value: str):\n",
    "    max_value = 0\n",
    "    for word in word_set:\n",
    "        current_word_max_value = ref_df.loc[(word), search_value]\n",
    "        if current_word_max_value > max_value:\n",
    "            max_value = current_word_max_value\n",
    "    return max_value\n",
    "\n",
    "# average age of acquisition --> how hard is the average word in the sentence\n",
    "def get_sentence_avg_value(word_set: Set[str], ref_df: pd.DataFrame, search_value: str):\n",
    "    total_value = 0\n",
    "    word_count = len(word_set)\n",
    "    for word in word_set:\n",
    "        current_word_value = ref_df.loc[(word), search_value]\n",
    "        total_value += current_word_value\n",
    "    try: \n",
    "        avg_val = total_value / word_count\n",
    "    except ZeroDivisionError:\n",
    "        avg_val = 0\n",
    "    return avg_val\n",
    "\n",
    "# quick test of functions\n",
    "assert get_sentence_max_value(['a','aardvark','abacus'], aoa_df_w_index, 'Freq_pm') == 20415.27\n",
    "assert get_sentence_avg_value(['a','aardvark','abacus'], aoa_df_w_index, 'Freq_pm') == ((20415.27 + 0.41 + 0.24) / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# this takes a while, like 9-10 minutes... but you only have to do it once\n",
    "\n",
    "# finds the max value in the sentence of each metric listed in `search_strings`\n",
    "\n",
    "search_strings = ['Nletters', 'Nphon', 'Nsyll', 'AoA_Kup', 'Perc_known', 'AoA_Kup_lem']\n",
    "metrics_dict = {}\n",
    "aoa_overlap_list = X['aoa_overlap'].to_list()\n",
    "        \n",
    "for search_string in search_strings:\n",
    "    current_vals_list = []\n",
    "    for idx, overlap_set in enumerate(aoa_overlap_list):\n",
    "        if idx % 100000 == 0:\n",
    "            print(f'Finished word {idx}, search string {search_string}')\n",
    "        # max vals\n",
    "        current_val = get_sentence_max_value(word_set=overlap_set, ref_df=aoa_df_w_index, search_value=search_string)\n",
    "        current_vals_list.append(current_val)\n",
    "        \n",
    "    current_dict_key = search_string + '_max'\n",
    "    metrics_dict[current_dict_key] = current_vals_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the dict into a df\n",
    "aoa_max_metrics_df = pd.DataFrame.from_dict(metrics_dict)\n",
    "# should have same number of rows as words in X\n",
    "print(f'Aoa Max Metrics DF shape: {aoa_max_metrics_df.shape}')\n",
    "aoa_max_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(X.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the df to the existing X df\n",
    "# X = X.merge(aoa_max_metrics_df, left_index=True, right_index=True)\n",
    "X = pd.concat([X, aoa_max_metrics_df], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# same as above, just done in a new cell for convenience/clarity\n",
    "# this also takes a while, like 6-7 minutes...\n",
    "\n",
    "# finds the avg value in the sentence of each metric listed in `search_strings`\n",
    "\n",
    "search_strings = ['Nletters', 'Nphon', 'Nsyll', 'AoA_Kup', 'Perc_known', 'AoA_Kup_lem']\n",
    "metrics_dict = {}\n",
    "aoa_overlap_list = X['aoa_overlap'].to_list()\n",
    "        \n",
    "for search_string in search_strings:\n",
    "    current_vals_list = []\n",
    "    for idx, overlap_set in enumerate(aoa_overlap_list):\n",
    "        if idx % 100000 == 0:\n",
    "            print(f'Finished word {idx}, search string {search_string}')\n",
    "        # avg vals\n",
    "        current_val = get_sentence_avg_value(word_set=overlap_set, ref_df=aoa_df_w_index, search_value=search_string)\n",
    "        current_vals_list.append(current_val)\n",
    "        \n",
    "    current_dict_key = search_string + '_avg'\n",
    "    metrics_dict[current_dict_key] = current_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoa_avg_metrics_df = pd.DataFrame.from_dict(metrics_dict)\n",
    "# should have same number of rows as words in X\n",
    "print(f'Aoa Max Metrics DF shape: {aoa_avg_metrics_df.shape}')\n",
    "aoa_avg_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, aoa_avg_metrics_df], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['aoa_overlap'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the concreteness file\n",
    "concreteness_path = os.path.join(project_base, 'data', 'Concreteness_ratings_Brysbaert_et_al_BRM.txt')\n",
    "concreteness_df = pd.read_csv(concreteness_path, sep='\\t')\n",
    "concreteness_df.fillna(0, inplace=True)\n",
    "concreteness_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_df_w_index = concreteness_df.set_index(['Word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_word_set = set(concreteness_df.Word.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['conc_overlap'] = X.sentence_word_list.apply(lambda a: set(a).intersection(conc_word_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# pretty fast, only takes 5-6 minutes\n",
    "\n",
    "# finds the max value in the sentence of each metric listed in `search_strings`\n",
    "\n",
    "search_strings = ['Bigram', 'Conc.M', 'Conc.SD', 'Unknown', 'Total', 'Percent_known', 'SUBTLEX']\n",
    "metrics_dict = {}\n",
    "conc_overlap_list = X['conc_overlap'].to_list()\n",
    "        \n",
    "for search_string in search_strings:\n",
    "    current_vals_list = []\n",
    "    for idx, overlap_set in enumerate(conc_overlap_list):\n",
    "        if idx % 100000 == 0:\n",
    "            print(f'Finished word {idx}, search string {search_string}')\n",
    "        # max vals\n",
    "        current_val = get_sentence_max_value(word_set=overlap_set, ref_df=conc_df_w_index, search_value=search_string)\n",
    "        current_vals_list.append(current_val)\n",
    "        \n",
    "    current_dict_key = search_string + '_max'\n",
    "    metrics_dict[current_dict_key] = current_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_max_metrics_df = pd.DataFrame.from_dict(metrics_dict)\n",
    "# should have same number of rows as words in X\n",
    "print(f'Conc Max Metrics DF shape: {conc_max_metrics_df.shape}')\n",
    "conc_max_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = pd.concat([X, conc_max_metrics_df], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# also pretty fast, only takes 1-2 minutes\n",
    "\n",
    "# finds the avg value in the sentence of each metric listed in `search_strings`\n",
    "\n",
    "search_strings = ['Bigram', 'Conc.M', 'Conc.SD', 'Unknown', 'Total', 'Percent_known', 'SUBTLEX']\n",
    "metrics_dict = {}\n",
    "conc_overlap_list = X['conc_overlap'].to_list()\n",
    "        \n",
    "for search_string in search_strings:\n",
    "    current_vals_list = []\n",
    "    for idx, overlap_set in enumerate(conc_overlap_list):\n",
    "        if idx % 100000 == 0:\n",
    "            print(f'Finished word {idx}, search string {search_string}')\n",
    "        # max vals\n",
    "        current_val = get_sentence_max_value(word_set=overlap_set, ref_df=conc_df_w_index, search_value=search_string)\n",
    "        current_vals_list.append(current_val)\n",
    "        \n",
    "    current_dict_key = search_string + '_avg'\n",
    "    metrics_dict[current_dict_key] = current_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_avg_metrics_df = pd.DataFrame.from_dict(metrics_dict)\n",
    "# should have same number of rows as words in X\n",
    "print(f'Conc Avg Metrics DF shape: {conc_avg_metrics_df.shape}')\n",
    "conc_avg_metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, conc_avg_metrics_df], axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the columns used for feature generation, but are not actually features\n",
    "\n",
    "# X.drop(['original_text', 'sentence_word_list', 'conc_overlap'], inplace=True, axis=1)\n",
    "X.drop(['sentence_word_list', 'conc_overlap'], inplace=True, axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_X = X.iloc[-kaggle_full_df.shape[0]:,:].copy()\n",
    "kaggle_y = y.iloc[-kaggle_full_df.shape[0]:].copy()\n",
    "print(kaggle_X.shape)\n",
    "print(kaggle_y.shape)\n",
    "assert kaggle_X.shape[0] == kaggle_full_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.iloc[:-kaggle_full_df.shape[0],:].copy()\n",
    "print(X.shape)\n",
    "y = y.iloc[:-kaggle_full_df.shape[0]].copy()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df to disk, next time we will just read it so we dont have to wait for all the processing\n",
    "X.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'X_updated.csv'), index=False)\n",
    "y.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'y_updated.csv'), index=False)\n",
    "kaggle_X.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'kaggle_X_updated.csv'), index=False)\n",
    "kaggle_y.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'kaggle_y_updated.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip To Here If Feature Creation Complete\n",
    "\n",
    "<a id='load_x'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dfs in\n",
    "\n",
    "X = pd.read_csv(os.path.join(project_base, 'data', 'cleaned_data','X_updated.csv'))\n",
    "y = pd.read_csv(os.path.join(project_base, 'data', 'cleaned_data','y_updated.csv'))\n",
    "kaggle_X = pd.read_csv(os.path.join(project_base, 'data', 'cleaned_data','kaggle_X_updated.csv'))\n",
    "kaggle_y = pd.read_csv(os.path.join(project_base, 'data', 'cleaned_data','kaggle_y_updated.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kaggle_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Word Vector Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_items = []\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "for b in tqdm(X['original_text']):\n",
    "    tokenized_train_items.append([a for a in re.findall('(\\w+)', b) if a.lower() not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wp = gensim.models.KeyedVectors.load(os.path.join(project_base, 'models','wikipedia.100.word-vecs.kv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_texts, word_vectors): \n",
    "    results = []\n",
    "    for doc in tokenized_texts:\n",
    "        current_vec = []\n",
    "        for word in doc:\n",
    "            try:\n",
    "                current_vec.append(word_vectors.wv[word])\n",
    "            except KeyError:\n",
    "                continue\n",
    "        if len(current_vec) == 0:\n",
    "            results.append(np.zeros(model_wp.vector_size))\n",
    "        else:\n",
    "            results.append(np.array(current_vec).mean(axis=0))\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, model_wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(project_base, 'data', 'cleaned_data','average_word_vecs'), X_train_wp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip to Here is WV Features Already Created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_wvs = np.load(os.path.join(project_base, 'data', 'cleaned_data','average_word_vecs.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data with full 100-dimensional WV features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_cols = [f'wv_col_{i}' for i in range(100)]\n",
    "X_full_wvs = pd.concat([X, pd.DataFrame(avg_wvs[:len(X), :], columns = wv_cols)], axis=1)\n",
    "print(f'Full Df with word vectors shape: {X_full_wvs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full_kaggle_wvs = pd.concat([kaggle_X, pd.DataFrame(avg_wvs[len(X):, :], columns = wv_cols)], axis=1)\n",
    "print(f'Full Df with word vectors shape: {X_full_kaggle_wvs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduced Vectors via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(avg_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 101):\n",
    "    print(f'{i} Components explain {pca.explained_variance_ratio_[:i].sum()*100:.2f}% variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = 30\n",
    "pca = PCA(n_components=pca_components)\n",
    "pca.fit(avg_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_pca_cols = [f'wv_pca_cols{i}' for i in range(pca_components)]\n",
    "X_pca_wvs = pd.concat([X, pd.DataFrame(pca.transform(avg_wvs[:len(X), :]), columns = wv_pca_cols)], axis=1)\n",
    "print(f'Full Df with word vectors shape: {X_pca_wvs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca_kaggle_wvs = pd.concat([kaggle_X, pd.DataFrame(pca.transform(avg_wvs[len(X):, :]), columns = wv_pca_cols)], axis=1)\n",
    "print(f'Full Df with word vectors shape: {X_full_kaggle_wvs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "X_pca_wvs.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'X_pca_updated.csv'), index=False)\n",
    "X_pca_kaggle_wvs.to_csv(os.path.join(project_base, 'data', 'cleaned_data', 'kaggle_X_pca_updated.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
