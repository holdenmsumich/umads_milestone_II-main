{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "overhead-mumbai",
   "metadata": {},
   "source": [
    "# Topic Modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "\n",
    "import gensim\n",
    "from gensim.models import TfidfModel\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-activation",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_base = os.path.dirname(os.path.realpath('.'))\n",
    "print(f'Project base path: {project_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-advancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could possibly combine the test set to get an even larger pool of words\n",
    "data_path = os.path.join(project_base, 'data', 'WikiLarge_Train.csv')\n",
    "full_df = pd.read_csv(data_path)\n",
    "print(f'full_df column names: {list(full_df)}')\n",
    "print(f'full training data df shape: {full_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-piece",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = full_df[['original_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check size\n",
    "print(len(text_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-collapse",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text to lowercase\n",
    "text_df['original_text'] = text_df['original_text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace hyphens with spaces\n",
    "text_df['original_text'] = text_df['original_text'].str.replace('[-]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "text_df['original_text'] = text_df['original_text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove multiple spaces\n",
    "text_df['original_text'] = text_df['original_text'].str.replace('\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem and lemmatize words \n",
    "# Snowball stemmer is a bit more agressive than porter stemmer\n",
    "# TODO: Try getting bigrams and trigrams\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def lemmatize(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def stem(text):\n",
    "    return SnowballStemmer('english').stem(text)\n",
    "\n",
    "def tokenize_and_preprocess(text):\n",
    "    \n",
    "    # tokenize words and remove any that have 3 or less letters\n",
    "    result = [stem(lemmatize(token)) for token in word_tokenize(text) if token not in stop_words and len(token) > 3]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check for document 500\n",
    "sample = text_df.iloc[500][0]\n",
    "\n",
    "words = [word for word in sample.split(' ')]\n",
    "\n",
    "\n",
    "print('Original Document:')\n",
    "print(words)\n",
    "print('Document After Tokenization, Stemming, and Lemmatization: ')\n",
    "print(tokenize_and_preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#map function to text and examine at processed sentences\n",
    "processed_sentences = text_df['original_text'].map(tokenize_and_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-sheriff",
   "metadata": {},
   "source": [
    "## Step 3: Create Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create gensim dictionary to get word count\n",
    "gensim_dictionary = gensim.corpora.Dictionary(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out words that are very rare and very common\n",
    "# no_below = words that appear less than n times\n",
    "# no_above words that appear in more than tselected % of documents\n",
    "\n",
    "gensim_dictionary.filter_extremes(no_below=5, no_above=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [gensim_dictionary.doc2bow(sentence) for sentence in processed_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check what example sentence looks like\n",
    "sample = [[(gensim_dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-traffic",
   "metadata": {},
   "source": [
    "## Step 4: Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find the optimum number of topics where coherence score is the highest\n",
    "#this takes a really long time to run. Uncomment the code \n",
    "\n",
    "\n",
    "def find_optimum_no_topics(dic, corpus, text, limit, start=2, step=2):\n",
    "    \n",
    "    model_coherence_scores = []\n",
    "    models = []\n",
    "    perplexity_scores = []\n",
    "    for num_topics in tqdm(range(start, limit, step)):\n",
    "        \n",
    "        # Build LDA model. Multicore is faster\n",
    "        lda = gensim.models.LdaMulticore(corpus,\n",
    "                                         id2word=dic,\n",
    "                                         num_topics=num_topics,\n",
    "                                         passes=2, \n",
    "                                         workers=2,\n",
    "                                         random_state=17)\n",
    "        models.append(lda)\n",
    "        coherence_model = CoherenceModel(model=lda, texts=text, dictionary=dic, coherence='c_v')\n",
    "        model_coherence_scores.append(coherence_model.get_coherence())\n",
    "        perplexity_scores.append(lda.log_perplexity(corpus)) # returns perplexity bound, later np.exp2(-bound) is applied\n",
    "    return models, model_coherence_scores, perplexity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this takes about 20 mins to run using an i9-10900k CPU, times may be significantly longer with other CPUs.\n",
    "# # Therefore, it is commented out. Take my word for it that the optimum number of topics is 22. LDAmulticore models are not 100% reproducible even with random_state, so the coherence scores may vary but are generally close.\n",
    "# models, coherence_scores, perplexity_scores = find_optimum_no_topics(gensim_dictionary, corpus, processed_sentences, 50, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply np.exp2 transformation\n",
    "# def calc_perplexity(x):\n",
    "#     return np.exp2(x)\n",
    "# pscores = list(map(calc_perplexity, perplexity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "pscores = [0.002863704297799762,\n",
    " 0.002811022226120487,\n",
    " 0.0014841978570930149,\n",
    " 0.0011133278299366141,\n",
    " 0.0008427106743769833,\n",
    " 0.0006268748525414524,\n",
    " 0.0004645755247013632,\n",
    " 0.00034550270074056255,\n",
    " 0.0002564365410782232,\n",
    " 0.00018780669786111197]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are the scores returned from executing the cell above\n",
    "coherence_scores = [0.16895017893660008,\n",
    " 0.4037807434997028,\n",
    " 0.4140849990233262,\n",
    " 0.4406477190626243,\n",
    " 0.474506627250172,\n",
    " 0.4464699825189897,\n",
    " 0.4606479110595841,#\n",
    " 0.43374942861540317,\n",
    " 0.42031969686544524,\n",
    " 0.397537490213966]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coherence scores\n",
    "limit = 50; start=2; step=5\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_scores)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"Coherenec Score\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coherence scores\n",
    "limit = 50; start=2; step=5\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, pscores)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Perplexity score\")\n",
    "plt.legend((\"Perplexity Score\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normally we could just take the index for the model since each model is saved in the \"models\" list. Like this:\n",
    "\n",
    "# optimal_model = models[4]\n",
    "\n",
    "# However, that would require you to run find_optimum_no_topics(). We will just run the model once below using the\n",
    "# optimum number of topics that was originally extracted with find_optimum_no_topics() to get a model to display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# takes aboiut 1 minute\n",
    "\n",
    "num_topics = 22\n",
    "# Build LDA model. Multicore is faster\n",
    "lda = gensim.models.LdaMulticore(corpus,\n",
    "                                 id2word=gensim_dictionary,\n",
    "                                 num_topics=num_topics,\n",
    "                                 passes=2, \n",
    "                                 workers=2,\n",
    "                                 random_state=17)\n",
    "# Print the Keywords\n",
    "print(lda.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-posting",
   "metadata": {},
   "source": [
    "## Step 5: Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display weights for each topic\n",
    "for idx, topic in lda.print_topics(-1):\n",
    "    print(f'Topic: {idx} \\nWords: {topic}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rankings for example 500\n",
    "lda[corpus[500]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-helping",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda, corpus, gensim_dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-cuisine",
   "metadata": {},
   "source": [
    "## Step 6: Add topic number as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the topic # with the highest percentage\n",
    "def extract_topic(idx):\n",
    "    x = lda[corpus[idx]]\n",
    "    return tuple(max(x, key=lambda x:x[1]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-wrestling",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_topic(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df['index'] = text_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function to extract the topic and use as another feature in supervised learning\n",
    "full_df['topic'] = text_df['index'].apply(extract_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv(os.path.join(project_base, 'data', 'unsupervised_data', 'WikiLarge_Train_With_Topics.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-conditions",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "Demonstration of topic modeling with Gensim's LDA Multicore model came from [this lecture](https://www.youtube.com/watch?v=JznDBeqS1lg&ab_channel=GradientGroup) by Carlos Lara. This lecture helped us to understand the best hyperparameters for a Gensim LDA model and how to use it effectively with the given dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
